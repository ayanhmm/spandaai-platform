# Platform Services for docker version of services
    # Hugging Face Token for vLLM services
    HF_TOKEN=your_hf_token_here

    # # VLLM Services
    # VLLM_URL_FOR_ANALYSIS=http://vllmnemotrontext:8001/v1/chat/completions
    # VLLM_URL_FOR_SUMMARY=http://vllmnemotrontext:8001/v1/chat/completions
    # VLLM_URL_FOR_IMAGE=http://vllmqwenvision:8002/v1/chat/completions
    # VLLM_URL_FOR_SCORING=http://vllmnemotrontext:8001/v1/chat/completions
    # VLLM_URL_FOR_EXTRACTION=http://vllmnemotrontext:8001/v1/chat/completions

    # # VLLM Models
    # VLLM_MODEL_FOR_ANALYSIS=AMead10/Llama-3.2-3B-Instruct-AWQ
    # VLLM_MODEL_FOR_EXTRACTION=AMead10/Llama-3.2-3B-Instruct-AWQ
    # VLLM_MODEL_FOR_SUMMARY=AMead10/Llama-3.2-3B-Instruct-AWQ
    # VLLM_MODEL_FOR_IMAGE=Qwen/Qwen2-VL-2B-Instruct-AWQ
    # VLLM_MODEL_FOR_SCORING=AMead10/Llama-3.2-3B-Instruct-AWQ

    #############OLLAMA PARAMS###################
    OLLAMA_URL = "http://host.docker.internal:11434"
    OLLAMA_MODEL_FOR_ANALYSIS = "llama3.1"            
    OLLAMA_MODEL_FOR_EXTRACTION = "llama3.1"            
    OLLAMA_MODEL_FOR_SUMMARY = "llama3.1"            
    OLLAMA_MODEL_FOR_IMAGE = "gemma3:4b"
    OLLAMA_MODEL_FOR_SCORING = "llama3.1"

