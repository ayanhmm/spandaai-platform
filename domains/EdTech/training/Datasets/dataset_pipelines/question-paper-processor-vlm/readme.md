

---

# âœ¨ğŸ“š **Question Paper Processor** â€“ *Powering the Future of Fine-Tuned LLMs*

Transform raw, unstructured academic question papers into beautifully structured, machine-readable datasets tailored for **Large Language Model (LLM) fine-tuning**.  
Whether you're an **AI researcher**, **educator**, or **institutional innovator**, the **Question Paper Processor** is your all-in-one pipeline to supercharge curriculum-specific LLMs.

---

## ğŸ“˜ **Table of Contents**
1. [ğŸ” Overview](#-overview)  
2. [ğŸš€ Features](#-features)  
3. [âš™ï¸ Installation](#-installation)  
4. [ğŸ›  Usage](#-usage)  
5. [ğŸ“Š Expected Output](#-expected-output)  
6. [ğŸ“‚ Directory Structure](#-directory-structure)  
7. [ğŸ“¦ Dependencies](#-dependencies)  
8. [ğŸ¤– LLM Configuration](#-llm-configuration)

---

## ğŸ” **Overview**

The **Question Paper Processor** is an intelligent, end-to-end system that:
- ğŸ“„ Converts DOCX, PPTX, HTML, and Markdown files into PDFs.
- ğŸ§  Extracts clean, structured text from PDFs â€” including complex mathematical notation (converted to LaTeX).
- ğŸ§¾ Automatically detects metadata (Course No., Course Title, Marks).
- ğŸ§® Converts equations into accurate LaTeX syntax.
- ğŸ§  Uses **LLMs** to infer the **topic** for every question.
- ğŸ“Š Outputs pristine, ready-to-train datasets in **CSV** and **JSON** formats â€” perfectly formatted for **LLM fine-tuning**.

---

## ğŸš€ **Features**

âœ¨ **Multi-Format Support** â€“ Seamlessly processes DOCX, PPTX, HTML, Markdown, and PDF files.

ğŸ§  **LLM-Powered Intelligence** â€“ Uses vision and instruction models to extract structure, infer topics, and detect metadata.

ğŸ“ **LaTeX-Enhanced Output** â€“ Ensures math expressions are LaTeX-ready for accurate rendering and training.

ğŸ¯ **High-Quality Dataset Creation** â€“ Outputs optimized datasets with `instruction`, `input`, `question`, `marks`, `topics`, and more.

ğŸ›  **Robust Error Handling** â€“ Logs all operations in detail, helping you debug and iterate quickly.

ğŸŒ **Dual Backend Support** â€“ Compatible with both **Ollama** and **VLLM** backends for flexible model orchestration.

---

## âš™ï¸ **Installation**

### ğŸ§¾ Prerequisites
1. ğŸ **Python 3.10**: Ensure Python 3.10 is installed.
2. ğŸ”§ **System Dependencies**: `LibreOffice` and `wkhtmltopdf` for document conversion.

### ğŸ“¥ Install Steps

```bash
# 1. Clone the repository
git clone git@github.com:spandaai/spandaai-platform.git
cd spandaai-platform/domains/EdTech/training/Datasets/dataset_pipelines/question_paper_processor_vlm
 ```

```bash
# 2. Run the installation script
chmod +x installation.sh
./installation.sh
 ```
  This script will:
   - Verify Python 3.10 installation.
   - Install system dependencies (`LibreOffice`, `wkhtmltopdf`).
   - Set up a Python virtual environment.
   - Install Python dependencies from `requirements.txt`.

```bash
# 3. Activate your environment
source venv/bin/activate
pip list  # Confirm packages are installed
```

---

## ğŸ›  **Usage**

### ğŸ“ Step 1: Add Your Files
Place all question paper files (`.pdf`, `.docx`, `.pptx`, `.html`, `.md`) in the `question_papers/` folder.

### âš™ï¸ Step 2: Set Environment Variables
Update `.env` to choose between **Ollama** (default) or **VLLM**.

```env
# Default: Ollama (locally running)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL_FOR_OCR=llama3.2-vision
OLLAMA_MODEL_FOR_EXTRACTION=llama3.2-vision
OLLAMA_MODEL_FOR_TOPIC=llama3.2-vision

# Option: Uncomment to use VLLM
# VLLM_URL_FOR_OCR=http://vllmnemotrontext:8001/v1/chat/completions
# VLLM_MODEL_FOR_OCR=AMead10/Llama-3.2-3B-Instruct-AWQ
```

Ensure your chosen LLM server is up and models are pulled.

### â–¶ï¸ Step 3: Run the Script

```bash
python qp_dataset_vlm.py
```

### ğŸ” Step 4: Explore Outputs
- Extracted text â†’ `final_stack/text_converted/`
- Final datasets â†’ `fine_tuning_dataset.csv`, `fine_tuning_dataset.json`
- Logs â†’ `qp_dataset.log`

---

### **Intermediate Files**
ğŸ“‚ **PDF Files** â€“ Converted from DOCX, PPTX, HTML, Markdown â†’ `final_stack/pdf_converted/`

ğŸ“‚ **Text Files** â€“ Extracted text from PDFs â†’ `final_stack/text_converted/`

---


## ğŸ“Š **Expected Output**

### **Final Dataset: `fine_tuning_dataset.csv`**
| Field          | Description                                          |
|---------------|--------------------------------------------------|
| `instruction`  | Instruction for generating similar questions.    |
| `input`        | Context input for question generation.           |
| `question`     | Extracted question text.                        |
| `course_no`    | Course number (e.g., CS101).                     |
| `course_title` | Course title (e.g., Introduction to AI).        |
| `marks`        | Marks allocated to the question.                |
| `topic`        | Inferred topic of the question.                 |
| `metadata_tag` | Unique document identifier.                     |



### ğŸ§¾ Sample CSV Output
| instruction               | input                                           | question                                       | course_no | course_title         | marks | topic           | metadata_tag |
|---------------------------|--------------------------------------------------|------------------------------------------------|-----------|-----------------------|-------|------------------|---------------|
| Act as an expert in question generation...    | Generate a question for the course id...   | What is the time complexity of binary search? | CS101     | Algorithms            | 10    | Binary Search    | a1b2c3d4      |

### ğŸ“ Intermediate Artifacts
- âœ… `final_stack/pdf_converted/` â†’ All input files converted to PDF.
- âœ… `final_stack/text_converted/` â†’ Cleaned & structured text output.
- âœ… `qp_dataset.log` â†’ Detailed execution log for full transparency.

---

## ğŸ“‚ **Directory Structure**
```
question-paper-processor/
â”œâ”€â”€ installation.sh               # One-step setup
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ qp_dataset.py                 # Core processing logic
â”œâ”€â”€ .env                          # LLM configuration file
â”œâ”€â”€ question_papers/              # Input files
â”œâ”€â”€ final_stack/                  # All generated outputs
â”‚   â”œâ”€â”€ pdf_converted/            # PDFs from input formats
â”‚   â”œâ”€â”€ text_converted/           # Extracted text files
â”œâ”€â”€ fine_tuning_dataset.csv       # Final dataset for training
â”œâ”€â”€ fine_tuning_dataset.json      # Same dataset in JSON format
â””â”€â”€ qp_dataset.log                # Logs for all pipeline steps
```

---

## ğŸ“¦ **Dependencies**

### ğŸ–¥ System
- ğŸ–¥ **LibreOffice** â€“ Converts DOCX, PPTX to PDF.
- ğŸŒ **wkhtmltopdf** â€“ Converts HTML, Markdown to PDF.

### ğŸ Python
Install with:

```bash
pip install -r requirements.txt
```

Key packages:
- `PyMuPDF` â€“ PDF parsing.
- `tqdm` â€“ Beautiful progress bars.
- `httpx` â€“ Async LLM calls.
- `dotenv`, `json5`, `logging`, `asyncio` â€“ Environment management, logging, and async magic.

---

## ğŸ¤– **LLM Configuration**

### ğŸ”§ Ollama (Default)
- Local URL: `http://localhost:11434`
- Models used: `llama3.2-vision`
```bash
ollama pull llama3.2-vision
```

### ğŸ”„ Switch to VLLM
Update `.env`:
```env
VLLM_URL_FOR_OCR=http://vllmnemotrontext:8001/v1/chat/completions
VLLM_MODEL_FOR_OCR=AMead10/Llama-3.2-3B-Instruct-AWQ
```

ğŸ’¡ **Auto-Fallback Logic** â€“ If both are configured, **VLLM is prioritized**. If neither is running, the script exits with a warning.

---

ğŸ“ **Train Smarter. Fine-Tune Faster. Build Better.**  
With **Question Paper Processor**, your LLMs learn from the best: real academic content, cleanly structured and semantically enriched.

---

ğŸ”¥ **Ready to revolutionize how your LLM learns?**  
**Letâ€™s process some papers!** ğŸ§ ğŸ“„

---