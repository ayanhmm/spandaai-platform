{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c68a2b7-acff-4f74-a372-05a48fc2be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring sensitive variables\n",
    "video_bucket_name = 'mybucket'\n",
    "minio_ip = \"172.18.0.4\"\n",
    "# Add IP Address of your MinIO server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361dd79-daf5-4456-a45e-9fc20953c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if folder properly imported\n",
    "import os\n",
    "folder_path = '/workspace/videos'\n",
    "files = os.listdir(folder_path)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a88e2495-2961-4318-8b03-ec9619451201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.client('s3', endpoint_url='http://minio:9000',\n",
    "                  aws_access_key_id='admin',\n",
    "                  aws_secret_access_key='password')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d994cda-da62-473f-979b-acc88424dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if bucket exists\n",
    "try:\n",
    "    s3.create_bucket(Bucket=video_bucket_name)\n",
    "    print(\"Bucket created.\")\n",
    "except s3.exceptions.BucketAlreadyOwnedByYou:\n",
    "    print(\"Bucket exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2619e133-8621-446a-b110-b5466c18496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload each file to S3 bucket\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        s3.upload_file(file_path, video_bucket_name, file_name)\n",
    "        print(f\"Uploaded {file_name} to {video_bucket_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73408c16-a676-43b7-9eae-07d6e0d31964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if sucessfully uploaded\n",
    "response = s3.list_objects_v2(Bucket=video_bucket_name)\n",
    "for obj in response.get('Contents', []):\n",
    "    print(obj['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "886848ca-1467-4887-a11c-bbbc414d1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- Uploading Metadata to Iceberg -----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d25468-ff87-4b07-adad-41dc0c260f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import cv2\n",
    "import boto3\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6c01b17-b40e-4ae7-96fd-49aa554e34f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bucket_name_in_minio = video_bucket_name\n",
    "\n",
    "CATALOG_URI = \"http://nessie:19120/api/v1\" ## Nessie Server URI\n",
    "WAREHOUSE = \"s3://\" + data_bucket_name_in_minio +\"/\" ## S3 Address to Write to\n",
    "STORAGE_URI = \"http://\"+ minio_ip +\":9000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5208368-3118-4f4f-9000-83b77081f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing SPARK\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setAppName('app_name')\n",
    "        .set('spark.jars.packages', 'org.postgresql:postgresql:42.7.3,org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.77.1,software.amazon.awssdk:bundle:2.24.8,software.amazon.awssdk:url-connection-client:2.24.8')\n",
    "        .set('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "        .set('spark.sql.catalog.nessie', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "        .set('spark.sql.catalog.nessie.uri', CATALOG_URI)\n",
    "        .set('spark.sql.catalog.nessie.ref', 'main')\n",
    "        .set('spark.sql.catalog.nessie.authentication.type', 'NONE')\n",
    "        .set('spark.sql.catalog.nessie.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\n",
    "        .set('spark.sql.catalog.nessie.s3.endpoint', STORAGE_URI)\n",
    "        .set('spark.sql.catalog.nessie.warehouse', WAREHOUSE)\n",
    "        .set('spark.sql.catalog.nessie.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')\n",
    ")\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d013caf-5e49-4b73-b8ae-1d35f813eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract metadata from a video file\n",
    "def extract_metadata_from_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n",
    "    width  = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    cap.release()\n",
    "    return duration, int(width), int(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114d4cc-2c5c-458d-b4e1-54218413cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract meta data from each video\n",
    "response = s3.list_objects_v2(Bucket=data_bucket_name_in_minio)\n",
    "\n",
    "video_metadata_list = []\n",
    "\n",
    "for obj in response.get('Contents', []):\n",
    "    key = obj['Key']\n",
    "    \n",
    "    if key.lower().endswith('.mp4'):\n",
    "        print(f\"{key}\")\n",
    "        temp_path = tempfile.NamedTemporaryFile(delete=False).name\n",
    "        s3.download_file(data_bucket_name_in_minio, key, temp_path)\n",
    "        try:\n",
    "            duration, width, height = extract_metadata_from_video(temp_path)\n",
    "            video_metadata_list.append((key, duration, width, height))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract metadata for {key}: {e}\")\n",
    "        \n",
    "        os.remove(temp_path)\n",
    "        print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4fea23-37ed-42da-a4ac-27ca477dc433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark DataFrame from metadata and upload to iceberg\n",
    "video_df = spark.createDataFrame(video_metadata_list, [\"filename\", \"duration_sec\", \"width\", \"height\"])\n",
    "video_df.writeTo(\"nessie.video_metadata\").createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e593918c-e904-441a-a5c1-305705b5152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Iceberg table from Nessie catalog to see if properly uploaded\n",
    "video_df = spark.read.table(\"nessie.video_metadata\")\n",
    "video_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2853aed-2120-4a10-9b3f-696ea42905ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
