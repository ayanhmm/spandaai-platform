# Ollama Configuration
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL_FOR_OCR=llama3.2-vision
OLLAMA_MODEL_FOR_EXTRACTION=llama3.2-vision
OLLAMA_MODEL_FOR_TOPIC=llama3.2-vision

# # VLLM Configuration
# VLLM_URL_FOR_OCR=http://vllmnemotrontext:8001/v1/chat/completions
# VLLM_URL_FOR_EXTRACTION=http://vllmnemotrontext:8001/v1/chat/completions
# VLLM_URL_FOR_TOPIC=http://vllmnemotrontext:8001/v1/chat/completions

# VLLM_MODEL_FOR_OCR=AMead10/Llama-3.2-3B-Instruct-AWQ
# VLLM_MODEL_FOR_EXTRACTION=AMead10/Llama-3.2-3B-Instruct-AWQ
# VLLM_MODEL_FOR_TOPIC=AMead10/Llama-3.2-3B-Instruct-AWQ